Grabbing training data...
Grabbing testing data...
Training model...
Training EPOCH 0:
/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn("torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.")
> /Users/kelseydoerksen/code/sudsaq-kelsey-research/research/kelsey/unet/train.py(310)train_probabilistic_model()
    309         ipdb.set_trace()
--> 310         experiment.log({
    311             'train NLL loss': train_loss,
600999.198275862
175.1713393638874
(501196.87109375, 183.35255432128906)
-99803
(502107.537109375, 178.24426651000977)
29059981.34375
tensor(354.9865, grad_fn=<AddBackward0>)
Traceback (most recent call last):
  File "/Users/kelseydoerksen/code/sudsaq-kelsey-research/research/kelsey/unet/run_pipeline.py", line 137, in <module>
    trained_model = train_probabilistic_model(model=unet,
  File "/Users/kelseydoerksen/code/sudsaq-kelsey-research/research/kelsey/unet/train.py", line 310, in train_probabilistic_model
    import ipdb
  File "/Users/kelseydoerksen/code/sudsaq-kelsey-research/research/kelsey/unet/train.py", line 310, in train_probabilistic_model
    import ipdb
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
If you suspect this is an IPython 8.7.0 bug, please report it at:
    https://github.com/ipython/ipython/issues
or send an email to the mailing list at ipython-dev@python.org
You can print a more detailed traceback right now with "%tb", or use "%debug"
to interactively debug it.
Extra-detailed tracebacks for bug-reporting purposes can be enabled via:
    %config Application.verbose_crash=True