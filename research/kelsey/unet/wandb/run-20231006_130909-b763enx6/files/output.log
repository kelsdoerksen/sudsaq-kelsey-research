Grabbing training data...
Grabbing testing data...
Training model...
Training EPOCH 0:
/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn("torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.")
Train NLL: 600999.198275862
Val NLL: 503206.541015625
Training EPOCH 1:
Train NLL: 76872.1546336207
Val NLL: 43143.044921875
Training EPOCH 2:
Train NLL: 68042.95076778017
Val NLL: 69692.57739257812
Training EPOCH 3:
Train NLL: 65652.3030711207
Val NLL: 50162.5283203125
Training EPOCH 4:
Train NLL: 59456.27310075431
Val NLL: 50122.14599609375
Training EPOCH 5:
Train NLL: 62714.3833512931
Val NLL: 67327.9853515625
Training EPOCH 6:
Train NLL: 57631.25680226293
Val NLL: 53725.890869140625
Training EPOCH 7:
Train NLL: 58352.43527747845
Val NLL: 53814.58837890625
Training EPOCH 8:
Train NLL: 53102.30987338362
Val NLL: 69763.27453613281
Training EPOCH 9:
Train NLL: 54502.30886314655
Val NLL: 41724.50622558594
Training EPOCH 10:
Train NLL: 62211.57650862069
Val NLL: 58577.63427734375
Training EPOCH 11:
Train NLL: 55664.40523976293
Val NLL: 47753.88684082031
Training EPOCH 12:
Train NLL: 59392.86712015086
Val NLL: 39974.06005859375
Training EPOCH 13:
Train NLL: 61876.166015625
Val NLL: 52967.338623046875
Training EPOCH 14:
Train NLL: 57953.190833782326
Val NLL: 40091.35595703125
Training EPOCH 15:
Train NLL: 58987.826037176725
Val NLL: 45300.96252441406
Training EPOCH 16:
Train NLL: 52770.47966056035
Val NLL: 35844.95397949219
Training EPOCH 17:
Train NLL: 50859.88291352371
Val NLL: 47573.281005859375
Training EPOCH 18:
Train NLL: 52999.11415678879
Val NLL: 40140.825439453125
Training EPOCH 19:
Train NLL: 63084.38860452586
Val NLL: 33864.7841796875
Training EPOCH 20:
Train NLL: 47313.84314385776
Val NLL: 47847.02685546875
Training EPOCH 21:
Train NLL: 60362.37015086207
Val NLL: 38871.12060546875
Training EPOCH 22:
Train NLL: 54775.723868534486
Val NLL: 30837.7275390625
Training EPOCH 23:
Train NLL: 53483.90294989224
Val NLL: 52826.08514404297
Training EPOCH 24:
Train NLL: 50314.48908943965
Val NLL: 56628.279541015625
Training EPOCH 25:
Train NLL: 58867.82596982759
Val NLL: 61707.0927734375
Training EPOCH 26:
Train NLL: 47060.750471443964
Val NLL: 40654.068603515625
Training EPOCH 27:
Train NLL: 54989.73605872845
Val NLL: 47673.22314453125
Training EPOCH 28:
Train NLL: 53640.161267510775
Val NLL: 67959.916015625
Training EPOCH 29:
Train NLL: 53826.89247710129
Val NLL: 40130.63757324219
Training EPOCH 30:
Train NLL: 53342.482017780174
Val NLL: 33429.778747558594
Training EPOCH 31:
Train NLL: 60469.61516702586
Val NLL: 36144.503173828125
Training EPOCH 32:
Train NLL: 52596.2329606681
Val NLL: 52708.435546875
Training EPOCH 33:
Train NLL: 52271.39611395474
Val NLL: 51307.3310546875
Training EPOCH 34:
Train NLL: 51521.4975080819
Val NLL: 34399.332763671875
Training EPOCH 35:
Train NLL: 54801.56081627155
Val NLL: 59769.05810546875
Training EPOCH 36:
Train NLL: 55369.75525323276
Val NLL: 43120.807678222656
Training EPOCH 37:
Train NLL: 56013.98430765086
Val NLL: 38841.749572753906
Training EPOCH 38:
Train NLL: 53766.84489493535
Val NLL: 45750.68786621094
Training EPOCH 39:
Train NLL: 49474.97151131465
Val NLL: 34404.8125
Training EPOCH 40:
Train NLL: 53838.406654094826
Val NLL: 54715.474609375
Training EPOCH 41:
Train NLL: 55324.557044719826
Val NLL: 36445.406494140625
Training EPOCH 42:
Train NLL: 55331.573477909486
Val NLL: 37978.28063964844
Training EPOCH 43:
Train NLL: 59001.535290948275
Val NLL: 35608.36022949219
Training EPOCH 44:
Train NLL: 52870.0142106681
Val NLL: 39692.30456542969
Training EPOCH 45:
Train NLL: 47466.15827047414
Val NLL: 27847.068237304688
Training EPOCH 46:
Train NLL: 53335.443595096986
Val NLL: 50547.85009765625
Training EPOCH 47:
Train NLL: 48393.187634698275
Val NLL: 32288.269409179688
Training EPOCH 48:
Train NLL: 48154.14682112069
Val NLL: 37392.15252685547
Training EPOCH 49:
Train NLL: 51569.58560075431
Val NLL: 40178.697265625
Training EPOCH 50:
Train NLL: 46368.032799030174
Val NLL: 43709.98876953125
Training EPOCH 51:
Train NLL: 53578.04317079741
Val NLL: 41367.878662109375
Training EPOCH 52:
Train NLL: 52073.89156788793
Val NLL: 41017.72131347656
Training EPOCH 53:
Train NLL: 52533.950767780174
Val NLL: 57637.46533203125
Training EPOCH 54:
Train NLL: 49354.306640625
Val NLL: 61601.009338378906
Training EPOCH 55:
Train NLL: 59219.73127693965
Val NLL: 51468.15344238281
Training EPOCH 56:
Train NLL: 54479.85028286638
Val NLL: 29053.34375
Training EPOCH 57:
Train NLL: 51444.56559806035
Val NLL: 48346.4306640625
Training EPOCH 58:
Train NLL: 48748.7485856681
Val NLL: 27267.272521972656
Training EPOCH 59:
Train NLL: 54786.21672952586
Val NLL: 27634.634826660156
Training EPOCH 60:
Train NLL: 52321.97481142241
Val NLL: 43872.17431640625
Training EPOCH 61:
Train NLL: 53315.45864762931
Val NLL: 46083.05908203125
Training EPOCH 62:
Train NLL: 52907.59287446121
Val NLL: 47079.114501953125
Training EPOCH 63:
Train NLL: 55001.78939924569
Val NLL: 50766.7490234375
Training EPOCH 64:
Train NLL: 45757.017982219826
Val NLL: 48119.333068847656
Training EPOCH 65:
Train NLL: 47633.92941810345
Val NLL: 35348.3408203125
Training EPOCH 66:
Train NLL: 46451.3412580819
Val NLL: 49538.48583984375
Training EPOCH 67:
Traceback (most recent call last):
  File "/Users/kelseydoerksen/code/sudsaq-kelsey-research/research/kelsey/unet/run_pipeline.py", line 137, in <module>
    trained_model = train_probabilistic_model(model=unet,
  File "/Users/kelseydoerksen/code/sudsaq-kelsey-research/research/kelsey/unet/train.py", line 297, in train_probabilistic_model
    pred_map_means, pred_map_log_vars = model(inputs)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/kelseydoerksen/code/sudsaq-kelsey-research/research/kelsey/unet/model/models.py", line 76, in forward
    x2 = self.drop(self.down1(x1))
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/kelseydoerksen/code/sudsaq-kelsey-research/research/kelsey/unet/model/unet_modules.py", line 69, in forward
    return self.maxpool_conv(x)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/kelseydoerksen/code/sudsaq-kelsey-research/research/kelsey/unet/model/unet_modules.py", line 32, in forward
    return self.double_conv(x)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/aq/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt